## Backend
# If unset, the app will fall back to a deterministic "mock" LLM so you can run the stack locally.
OPENAI_API_KEY=
GEMINI_API_KEY=
DEEPSEEK_API_KEY=
# Usually leave as-is (DeepSeek OpenAI-compatible endpoint)
DEEPSEEK_BASE_URL=https://api.deepseek.com

# Optional (enables web search when tasks have web_search_enabled=true)
TAVILY_API_KEY=

DATABASE_URL=sqlite:////app/data/promptoncron.db

# mock | openai | gemini | deepseek
LLM_PROVIDER=deepseek
# Known-working model for many keys (and in our container test): gemini-2.5-flash
DEFAULT_LLM_MODEL=gemini-2.5-flash

SCHEDULER_INTERVAL=10
WORKER_POLL_INTERVAL=2

## Frontend
VITE_API_URL=http://localhost:8000


